{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzzwKSL4Wor3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# pip install keras\n",
    "# pip install tensorflow\n",
    "# We'll borrow the `pad_sequences` utility function to do this.\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mE4a2IA2Wor5"
   },
   "outputs": [],
   "source": [
    "\n",
    "x = pd.read_csv('unstructure1.csv')\n",
    "x = x[['facility_id','inspection_text']]\n",
    "label = pd.read_csv('label.csv')\n",
    "label['label'] = label['High Risk'] - label['Low Risk']\n",
    "label['label'] = label['label'].apply(lambda x: 0 if x < 0 else x)\n",
    "label = label[['Federal Provider Number','avg_weekly_covid19_death_per_occupied_bed_pct_aggregate_max_final','label']]\n",
    "df = pd.merge(x, label, how='inner',  left_on='facility_id', right_on='Federal Provider Number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Py2un2yvWor6",
    "outputId": "b4a688ab-fc28-4335-a0be-6a121e3695d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111797, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgX0CV3uWor8"
   },
   "outputs": [],
   "source": [
    "max_seq_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onrAdLNPWosD",
    "outputId": "c41defd1-7052-4398-ae97-f86b483c6ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vU-L8BEYWosD"
   },
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "sentences = df.inspection_text.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imz-CgiRWosD",
    "outputId": "658f61e2-e2b8-4562-cd4d-c4c20a98be1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  admiss nurs note 4218 356 identifi 2 alert orient person place time verbal appropri surgic woundth nurs note 4218 1114 identifi dress chang perform left foot measur follow left thigh knee twelv 12 stapl area measur 8 centimet cm point left knee fortyseven 47 stapl area measur 30 cm left knee ankl twentyfour 24 stapl area measur 125 cm dress small amount serosanguin drainag 2 toler dress chang wellinterview treatmentwound nurs lpn 2 7319 1115 identifi respons monitor pressur ulcer andor wound weekli\n",
      "Tokenized:  ['ad', '##mis', '##s', 'nur', '##s', 'note', '421', '##8', '356', 'id', '##ent', '##if', '##i', '2', 'alert', 'orient', 'person', 'place', 'time', 'verbal', 'app', '##rop', '##ri', 'sur', '##gic', 'wound', '##th', 'nur', '##s', 'note', '421', '##8', '111', '##4', 'id', '##ent', '##if', '##i', 'dress', 'chang', 'perform', 'left', 'foot', 'me', '##as', '##ur', 'follow', 'left', 'thigh', 'knee', 't', '##we', '##l', '##v', '12', 'st', '##ap', '##l', 'area', 'me', '##as', '##ur', '8', 'cent', '##ime', '##t', 'cm', 'point', 'left', 'knee', 'forty', '##se', '##ven', '47', 'st', '##ap', '##l', 'area', 'me', '##as', '##ur', '30', 'cm', 'left', 'knee', 'an', '##k', '##l', 'twenty', '##fo', '##ur', '24', 'st', '##ap', '##l', 'area', 'me', '##as', '##ur', '125', 'cm', 'dress', 'small', 'amount', 'ser', '##osa', '##ng', '##uin', 'drain', '##ag', '2', 'to', '##ler', 'dress', 'chang', 'well', '##int', '##er', '##view', 'treatment', '##wo', '##und', 'nur', '##s', 'lp', '##n', '2', '73', '##19', '111', '##5', 'id', '##ent', '##if', '##i', 'res', '##pon', '##s', 'monitor', 'press', '##ur', 'ul', '##cer', 'and', '##or', 'wound', 'week', '##li']\n",
      "Token IDs:  [4748, 15630, 2015, 27617, 2015, 3602, 29403, 2620, 27509, 8909, 4765, 10128, 2072, 1016, 9499, 16865, 2711, 2173, 2051, 12064, 10439, 18981, 3089, 7505, 12863, 6357, 2705, 27617, 2015, 3602, 29403, 2620, 11118, 2549, 8909, 4765, 10128, 2072, 4377, 11132, 4685, 2187, 3329, 2033, 3022, 3126, 3582, 2187, 10120, 6181, 1056, 8545, 2140, 2615, 2260, 2358, 9331, 2140, 2181, 2033, 3022, 3126, 1022, 9358, 14428, 2102, 4642, 2391, 2187, 6181, 5659, 3366, 8159, 4700, 2358, 9331, 2140, 2181, 2033, 3022, 3126, 2382, 4642, 2187, 6181, 2019, 2243, 2140, 3174, 14876, 3126, 2484, 2358, 9331, 2140, 2181, 2033, 3022, 3126, 8732, 4642, 4377, 2235, 3815, 14262, 8820, 3070, 20023, 12475, 8490, 1016, 2000, 3917, 4377, 11132, 2092, 18447, 2121, 8584, 3949, 12155, 8630, 27617, 2015, 6948, 2078, 1016, 6421, 16147, 11118, 2629, 8909, 4765, 10128, 2072, 24501, 26029, 2015, 8080, 2811, 3126, 17359, 17119, 1998, 2953, 6357, 2733, 3669]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPY63HLoWosD",
    "outputId": "ee9a88cd-beda-4a9b-f582-b5bbe89435d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'admiss nurs note 4218 356 identifi 2 alert orient person place time verbal appropri surgic woundth nurs note 4218 1114 identifi dress chang perform left foot measur follow left thigh knee twelv 12 stapl area measur 8 centimet cm point left knee fortyseven 47 stapl area measur 30 cm left knee ankl twentyfour 24 stapl area measur 125 cm dress small amount serosanguin drainag 2 toler dress chang wellinterview treatmentwound nurs lpn 2 7319 1115 identifi respons monitor pressur ulcer andor wound weekli'"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['inspection_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqCuJKUDWosD",
    "outputId": "e34790c4-4f33-448f-a923-1d7b7ae07c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  admiss nurs note 4218 356 identifi 2 alert orient person place time verbal appropri surgic woundth nurs note 4218 1114 identifi dress chang perform left foot measur follow left thigh knee twelv 12 stapl area measur 8 centimet cm point left knee fortyseven 47 stapl area measur 30 cm left knee ankl twentyfour 24 stapl area measur 125 cm dress small amount serosanguin drainag 2 toler dress chang wellinterview treatmentwound nurs lpn 2 7319 1115 identifi respons monitor pressur ulcer andor wound weekli\n",
      "Token IDs: [101, 4748, 15630, 2015, 27617, 2015, 3602, 29403, 2620, 27509, 8909, 4765, 10128, 2072, 1016, 9499, 16865, 2711, 2173, 2051, 12064, 10439, 18981, 3089, 7505, 12863, 6357, 2705, 27617, 2015, 3602, 29403, 2620, 11118, 2549, 8909, 4765, 10128, 2072, 4377, 11132, 4685, 2187, 3329, 2033, 3022, 3126, 3582, 2187, 10120, 6181, 1056, 8545, 2140, 2615, 2260, 2358, 9331, 2140, 2181, 2033, 3022, 3126, 1022, 9358, 14428, 2102, 4642, 2391, 2187, 6181, 5659, 3366, 8159, 4700, 2358, 9331, 2140, 2181, 2033, 3022, 3126, 2382, 4642, 2187, 6181, 2019, 2243, 2140, 3174, 14876, 3126, 2484, 2358, 9331, 2140, 2181, 2033, 3022, 3126, 8732, 4642, 4377, 2235, 3815, 14262, 8820, 3070, 20023, 12475, 8490, 1016, 2000, 3917, 4377, 11132, 2092, 18447, 2121, 8584, 3949, 12155, 8630, 27617, 2015, 6948, 2078, 1016, 6421, 16147, 11118, 2629, 8909, 4765, 10128, 2072, 24501, 26029, 2015, 8080, 2811, 3126, 17359, 17119, 1998, 2953, 6357, 2733, 3669, 102]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "                        # This function also supports truncation and conversion\n",
    "                        # to pytorch tensors, but we need to do padding, so we\n",
    "                        # can't use these features :( .\n",
    "                        #max_length = 128,          # Truncate all sentences.\n",
    "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBzeHF3PWosE",
    "outputId": "803e840c-994a-4b8a-ee53-d74c9a7639f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  2480\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC-j_lRKWosE",
    "outputId": "04d9a4d8-0cc9-4abb-fc00-a36d17de8197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 64 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set the maximum sequence length.\n",
    "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
    "# maximum training sentence length of 47...\n",
    "MAX_LEN = 64\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ih9hX_sdWosE"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYySJ9WpWosE"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_d5vVfQTWosF"
   },
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype \n",
    "# for our model.\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0JEmZlVWosF"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjXhQpCkWosF",
    "outputId": "9d77d3f2-2b4a-42b3-d989-1c11aac66e25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSXDrZ_jWosF",
    "outputId": "cced2cd2-602d-4986-acb6-68dbf81810e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfejGcCRWosF"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcORnVNwWosF",
    "outputId": "756d10c5-6ceb-4e45-f852-42650929dcc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.LambdaLR at 0x7fc0ff135f98>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGHPVOqhWosG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vDl8ZDdWosG"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5Kfn5rmWosG",
    "outputId": "7535c9ae-822a-4eb2-db20-4070dfed3d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  3,145.    Elapsed: 0:00:23.\n",
      "  Batch    80  of  3,145.    Elapsed: 0:00:46.\n",
      "  Batch   120  of  3,145.    Elapsed: 0:01:09.\n",
      "  Batch   160  of  3,145.    Elapsed: 0:01:32.\n",
      "  Batch   200  of  3,145.    Elapsed: 0:01:55.\n",
      "  Batch   240  of  3,145.    Elapsed: 0:02:18.\n",
      "  Batch   280  of  3,145.    Elapsed: 0:02:41.\n",
      "  Batch   320  of  3,145.    Elapsed: 0:03:05.\n",
      "  Batch   360  of  3,145.    Elapsed: 0:03:28.\n",
      "  Batch   400  of  3,145.    Elapsed: 0:03:51.\n",
      "  Batch   440  of  3,145.    Elapsed: 0:04:14.\n",
      "  Batch   480  of  3,145.    Elapsed: 0:04:37.\n",
      "  Batch   520  of  3,145.    Elapsed: 0:05:00.\n",
      "  Batch   560  of  3,145.    Elapsed: 0:05:24.\n",
      "  Batch   600  of  3,145.    Elapsed: 0:05:47.\n",
      "  Batch   640  of  3,145.    Elapsed: 0:06:10.\n",
      "  Batch   680  of  3,145.    Elapsed: 0:06:33.\n",
      "  Batch   720  of  3,145.    Elapsed: 0:06:56.\n",
      "  Batch   760  of  3,145.    Elapsed: 0:07:20.\n",
      "  Batch   800  of  3,145.    Elapsed: 0:07:43.\n",
      "  Batch   840  of  3,145.    Elapsed: 0:08:06.\n",
      "  Batch   880  of  3,145.    Elapsed: 0:08:29.\n",
      "  Batch   920  of  3,145.    Elapsed: 0:08:52.\n",
      "  Batch   960  of  3,145.    Elapsed: 0:09:16.\n",
      "  Batch 1,000  of  3,145.    Elapsed: 0:09:39.\n",
      "  Batch 1,040  of  3,145.    Elapsed: 0:10:02.\n",
      "  Batch 1,080  of  3,145.    Elapsed: 0:10:25.\n",
      "  Batch 1,120  of  3,145.    Elapsed: 0:10:48.\n",
      "  Batch 1,160  of  3,145.    Elapsed: 0:11:12.\n",
      "  Batch 1,200  of  3,145.    Elapsed: 0:11:35.\n",
      "  Batch 1,240  of  3,145.    Elapsed: 0:11:58.\n",
      "  Batch 1,280  of  3,145.    Elapsed: 0:12:21.\n",
      "  Batch 1,320  of  3,145.    Elapsed: 0:12:45.\n",
      "  Batch 1,360  of  3,145.    Elapsed: 0:13:08.\n",
      "  Batch 1,400  of  3,145.    Elapsed: 0:13:31.\n",
      "  Batch 1,440  of  3,145.    Elapsed: 0:13:54.\n",
      "  Batch 1,480  of  3,145.    Elapsed: 0:14:18.\n",
      "  Batch 1,520  of  3,145.    Elapsed: 0:14:41.\n",
      "  Batch 1,560  of  3,145.    Elapsed: 0:15:04.\n",
      "  Batch 1,600  of  3,145.    Elapsed: 0:15:28.\n",
      "  Batch 1,640  of  3,145.    Elapsed: 0:15:51.\n",
      "  Batch 1,680  of  3,145.    Elapsed: 0:16:14.\n",
      "  Batch 1,720  of  3,145.    Elapsed: 0:16:38.\n",
      "  Batch 1,760  of  3,145.    Elapsed: 0:17:01.\n",
      "  Batch 1,800  of  3,145.    Elapsed: 0:17:24.\n",
      "  Batch 1,840  of  3,145.    Elapsed: 0:17:47.\n",
      "  Batch 1,880  of  3,145.    Elapsed: 0:18:11.\n",
      "  Batch 1,920  of  3,145.    Elapsed: 0:18:34.\n",
      "  Batch 1,960  of  3,145.    Elapsed: 0:18:57.\n",
      "  Batch 2,000  of  3,145.    Elapsed: 0:19:21.\n",
      "  Batch 2,040  of  3,145.    Elapsed: 0:19:44.\n",
      "  Batch 2,080  of  3,145.    Elapsed: 0:20:07.\n",
      "  Batch 2,120  of  3,145.    Elapsed: 0:20:30.\n",
      "  Batch 2,160  of  3,145.    Elapsed: 0:20:54.\n",
      "  Batch 2,200  of  3,145.    Elapsed: 0:21:17.\n",
      "  Batch 2,240  of  3,145.    Elapsed: 0:21:40.\n",
      "  Batch 2,280  of  3,145.    Elapsed: 0:22:04.\n",
      "  Batch 2,320  of  3,145.    Elapsed: 0:22:27.\n",
      "  Batch 2,360  of  3,145.    Elapsed: 0:22:50.\n",
      "  Batch 2,400  of  3,145.    Elapsed: 0:23:14.\n",
      "  Batch 2,440  of  3,145.    Elapsed: 0:23:37.\n",
      "  Batch 2,480  of  3,145.    Elapsed: 0:24:00.\n",
      "  Batch 2,520  of  3,145.    Elapsed: 0:24:24.\n",
      "  Batch 2,560  of  3,145.    Elapsed: 0:24:47.\n",
      "  Batch 2,600  of  3,145.    Elapsed: 0:25:10.\n",
      "  Batch 2,640  of  3,145.    Elapsed: 0:25:33.\n",
      "  Batch 2,680  of  3,145.    Elapsed: 0:25:57.\n",
      "  Batch 2,720  of  3,145.    Elapsed: 0:26:20.\n",
      "  Batch 2,760  of  3,145.    Elapsed: 0:26:43.\n",
      "  Batch 2,800  of  3,145.    Elapsed: 0:27:07.\n",
      "  Batch 2,840  of  3,145.    Elapsed: 0:27:30.\n",
      "  Batch 2,880  of  3,145.    Elapsed: 0:27:53.\n",
      "  Batch 2,920  of  3,145.    Elapsed: 0:28:16.\n",
      "  Batch 2,960  of  3,145.    Elapsed: 0:28:40.\n",
      "  Batch 3,000  of  3,145.    Elapsed: 0:29:03.\n",
      "  Batch 3,040  of  3,145.    Elapsed: 0:29:26.\n",
      "  Batch 3,080  of  3,145.    Elapsed: 0:29:50.\n",
      "  Batch 3,120  of  3,145.    Elapsed: 0:30:13.\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:30:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.69\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  3,145.    Elapsed: 0:00:23.\n",
      "  Batch    80  of  3,145.    Elapsed: 0:00:47.\n",
      "  Batch   120  of  3,145.    Elapsed: 0:01:10.\n",
      "  Batch   160  of  3,145.    Elapsed: 0:01:33.\n",
      "  Batch   200  of  3,145.    Elapsed: 0:01:57.\n",
      "  Batch   240  of  3,145.    Elapsed: 0:02:20.\n",
      "  Batch   280  of  3,145.    Elapsed: 0:02:43.\n",
      "  Batch   320  of  3,145.    Elapsed: 0:03:07.\n",
      "  Batch   360  of  3,145.    Elapsed: 0:03:30.\n",
      "  Batch   400  of  3,145.    Elapsed: 0:03:53.\n",
      "  Batch   440  of  3,145.    Elapsed: 0:04:17.\n",
      "  Batch   480  of  3,145.    Elapsed: 0:04:40.\n",
      "  Batch   520  of  3,145.    Elapsed: 0:05:03.\n",
      "  Batch   560  of  3,145.    Elapsed: 0:05:27.\n",
      "  Batch   600  of  3,145.    Elapsed: 0:05:50.\n",
      "  Batch   640  of  3,145.    Elapsed: 0:06:13.\n",
      "  Batch   680  of  3,145.    Elapsed: 0:06:37.\n",
      "  Batch   720  of  3,145.    Elapsed: 0:07:00.\n",
      "  Batch   760  of  3,145.    Elapsed: 0:07:23.\n",
      "  Batch   800  of  3,145.    Elapsed: 0:07:47.\n",
      "  Batch   840  of  3,145.    Elapsed: 0:08:10.\n",
      "  Batch   880  of  3,145.    Elapsed: 0:08:33.\n",
      "  Batch   920  of  3,145.    Elapsed: 0:08:57.\n",
      "  Batch   960  of  3,145.    Elapsed: 0:09:20.\n",
      "  Batch 1,000  of  3,145.    Elapsed: 0:09:43.\n",
      "  Batch 1,040  of  3,145.    Elapsed: 0:10:07.\n",
      "  Batch 1,080  of  3,145.    Elapsed: 0:10:30.\n",
      "  Batch 1,120  of  3,145.    Elapsed: 0:10:53.\n",
      "  Batch 1,160  of  3,145.    Elapsed: 0:11:17.\n",
      "  Batch 1,200  of  3,145.    Elapsed: 0:11:40.\n",
      "  Batch 1,240  of  3,145.    Elapsed: 0:12:03.\n",
      "  Batch 1,280  of  3,145.    Elapsed: 0:12:27.\n",
      "  Batch 1,320  of  3,145.    Elapsed: 0:12:50.\n",
      "  Batch 1,360  of  3,145.    Elapsed: 0:13:13.\n",
      "  Batch 1,400  of  3,145.    Elapsed: 0:13:37.\n",
      "  Batch 1,440  of  3,145.    Elapsed: 0:14:00.\n",
      "  Batch 1,480  of  3,145.    Elapsed: 0:14:23.\n",
      "  Batch 1,520  of  3,145.    Elapsed: 0:14:47.\n",
      "  Batch 1,560  of  3,145.    Elapsed: 0:15:10.\n",
      "  Batch 1,600  of  3,145.    Elapsed: 0:15:33.\n",
      "  Batch 1,640  of  3,145.    Elapsed: 0:15:57.\n",
      "  Batch 1,680  of  3,145.    Elapsed: 0:16:20.\n",
      "  Batch 1,720  of  3,145.    Elapsed: 0:16:43.\n",
      "  Batch 1,760  of  3,145.    Elapsed: 0:17:07.\n",
      "  Batch 1,800  of  3,145.    Elapsed: 0:17:30.\n",
      "  Batch 1,840  of  3,145.    Elapsed: 0:17:53.\n",
      "  Batch 1,880  of  3,145.    Elapsed: 0:18:17.\n",
      "  Batch 1,920  of  3,145.    Elapsed: 0:18:40.\n",
      "  Batch 1,960  of  3,145.    Elapsed: 0:19:03.\n",
      "  Batch 2,000  of  3,145.    Elapsed: 0:19:27.\n",
      "  Batch 2,040  of  3,145.    Elapsed: 0:19:50.\n",
      "  Batch 2,080  of  3,145.    Elapsed: 0:20:13.\n",
      "  Batch 2,120  of  3,145.    Elapsed: 0:20:37.\n",
      "  Batch 2,160  of  3,145.    Elapsed: 0:21:00.\n",
      "  Batch 2,200  of  3,145.    Elapsed: 0:21:23.\n",
      "  Batch 2,240  of  3,145.    Elapsed: 0:21:47.\n",
      "  Batch 2,280  of  3,145.    Elapsed: 0:22:10.\n",
      "  Batch 2,320  of  3,145.    Elapsed: 0:22:33.\n",
      "  Batch 2,360  of  3,145.    Elapsed: 0:22:57.\n",
      "  Batch 2,400  of  3,145.    Elapsed: 0:23:20.\n",
      "  Batch 2,440  of  3,145.    Elapsed: 0:23:43.\n",
      "  Batch 2,480  of  3,145.    Elapsed: 0:24:07.\n",
      "  Batch 2,520  of  3,145.    Elapsed: 0:24:30.\n",
      "  Batch 2,560  of  3,145.    Elapsed: 0:24:53.\n",
      "  Batch 2,600  of  3,145.    Elapsed: 0:25:17.\n",
      "  Batch 2,640  of  3,145.    Elapsed: 0:25:40.\n",
      "  Batch 2,680  of  3,145.    Elapsed: 0:26:03.\n",
      "  Batch 2,720  of  3,145.    Elapsed: 0:26:27.\n",
      "  Batch 2,760  of  3,145.    Elapsed: 0:26:50.\n",
      "  Batch 2,800  of  3,145.    Elapsed: 0:27:13.\n",
      "  Batch 2,840  of  3,145.    Elapsed: 0:27:37.\n",
      "  Batch 2,880  of  3,145.    Elapsed: 0:28:00.\n",
      "  Batch 2,920  of  3,145.    Elapsed: 0:28:23.\n",
      "  Batch 2,960  of  3,145.    Elapsed: 0:28:47.\n",
      "  Batch 3,000  of  3,145.    Elapsed: 0:29:10.\n",
      "  Batch 3,040  of  3,145.    Elapsed: 0:29:33.\n",
      "  Batch 3,080  of  3,145.    Elapsed: 0:29:57.\n",
      "  Batch 3,120  of  3,145.    Elapsed: 0:30:20.\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:30:34\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.69\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  3,145.    Elapsed: 0:00:23.\n",
      "  Batch    80  of  3,145.    Elapsed: 0:00:47.\n",
      "  Batch   120  of  3,145.    Elapsed: 0:01:10.\n",
      "  Batch   160  of  3,145.    Elapsed: 0:01:33.\n",
      "  Batch   200  of  3,145.    Elapsed: 0:01:57.\n",
      "  Batch   240  of  3,145.    Elapsed: 0:02:20.\n",
      "  Batch   280  of  3,145.    Elapsed: 0:02:43.\n",
      "  Batch   320  of  3,145.    Elapsed: 0:03:07.\n",
      "  Batch   360  of  3,145.    Elapsed: 0:03:30.\n",
      "  Batch   400  of  3,145.    Elapsed: 0:03:53.\n",
      "  Batch   440  of  3,145.    Elapsed: 0:04:17.\n",
      "  Batch   480  of  3,145.    Elapsed: 0:04:40.\n",
      "  Batch   520  of  3,145.    Elapsed: 0:05:03.\n",
      "  Batch   560  of  3,145.    Elapsed: 0:05:27.\n",
      "  Batch   600  of  3,145.    Elapsed: 0:05:50.\n",
      "  Batch   640  of  3,145.    Elapsed: 0:06:13.\n",
      "  Batch   680  of  3,145.    Elapsed: 0:06:37.\n",
      "  Batch   720  of  3,145.    Elapsed: 0:07:00.\n",
      "  Batch   760  of  3,145.    Elapsed: 0:07:23.\n",
      "  Batch   800  of  3,145.    Elapsed: 0:07:47.\n",
      "  Batch   840  of  3,145.    Elapsed: 0:08:10.\n",
      "  Batch   880  of  3,145.    Elapsed: 0:08:33.\n",
      "  Batch   920  of  3,145.    Elapsed: 0:08:57.\n",
      "  Batch   960  of  3,145.    Elapsed: 0:09:20.\n",
      "  Batch 1,000  of  3,145.    Elapsed: 0:09:43.\n",
      "  Batch 1,040  of  3,145.    Elapsed: 0:10:07.\n",
      "  Batch 1,080  of  3,145.    Elapsed: 0:10:30.\n",
      "  Batch 1,120  of  3,145.    Elapsed: 0:10:53.\n",
      "  Batch 1,160  of  3,145.    Elapsed: 0:11:17.\n",
      "  Batch 1,200  of  3,145.    Elapsed: 0:11:40.\n",
      "  Batch 1,240  of  3,145.    Elapsed: 0:12:03.\n",
      "  Batch 1,280  of  3,145.    Elapsed: 0:12:27.\n",
      "  Batch 1,320  of  3,145.    Elapsed: 0:12:50.\n",
      "  Batch 1,360  of  3,145.    Elapsed: 0:13:13.\n",
      "  Batch 1,400  of  3,145.    Elapsed: 0:13:37.\n",
      "  Batch 1,440  of  3,145.    Elapsed: 0:14:00.\n",
      "  Batch 1,480  of  3,145.    Elapsed: 0:14:23.\n",
      "  Batch 1,520  of  3,145.    Elapsed: 0:14:47.\n",
      "  Batch 1,560  of  3,145.    Elapsed: 0:15:10.\n",
      "  Batch 1,600  of  3,145.    Elapsed: 0:15:33.\n",
      "  Batch 1,640  of  3,145.    Elapsed: 0:15:57.\n",
      "  Batch 1,680  of  3,145.    Elapsed: 0:16:20.\n",
      "  Batch 1,720  of  3,145.    Elapsed: 0:16:44.\n",
      "  Batch 1,760  of  3,145.    Elapsed: 0:17:07.\n",
      "  Batch 1,800  of  3,145.    Elapsed: 0:17:30.\n",
      "  Batch 1,840  of  3,145.    Elapsed: 0:17:54.\n",
      "  Batch 1,880  of  3,145.    Elapsed: 0:18:17.\n",
      "  Batch 1,920  of  3,145.    Elapsed: 0:18:40.\n",
      "  Batch 1,960  of  3,145.    Elapsed: 0:19:04.\n",
      "  Batch 2,000  of  3,145.    Elapsed: 0:19:27.\n",
      "  Batch 2,040  of  3,145.    Elapsed: 0:19:50.\n",
      "  Batch 2,080  of  3,145.    Elapsed: 0:20:14.\n",
      "  Batch 2,120  of  3,145.    Elapsed: 0:20:37.\n",
      "  Batch 2,160  of  3,145.    Elapsed: 0:21:00.\n",
      "  Batch 2,200  of  3,145.    Elapsed: 0:21:24.\n",
      "  Batch 2,240  of  3,145.    Elapsed: 0:21:47.\n",
      "  Batch 2,280  of  3,145.    Elapsed: 0:22:10.\n",
      "  Batch 2,320  of  3,145.    Elapsed: 0:22:34.\n",
      "  Batch 2,360  of  3,145.    Elapsed: 0:22:57.\n",
      "  Batch 2,400  of  3,145.    Elapsed: 0:23:21.\n",
      "  Batch 2,440  of  3,145.    Elapsed: 0:23:44.\n",
      "  Batch 2,480  of  3,145.    Elapsed: 0:24:07.\n",
      "  Batch 2,520  of  3,145.    Elapsed: 0:24:31.\n",
      "  Batch 2,560  of  3,145.    Elapsed: 0:24:54.\n",
      "  Batch 2,600  of  3,145.    Elapsed: 0:25:17.\n",
      "  Batch 2,640  of  3,145.    Elapsed: 0:25:41.\n",
      "  Batch 2,680  of  3,145.    Elapsed: 0:26:04.\n",
      "  Batch 2,720  of  3,145.    Elapsed: 0:26:27.\n",
      "  Batch 2,760  of  3,145.    Elapsed: 0:26:51.\n",
      "  Batch 2,800  of  3,145.    Elapsed: 0:27:14.\n",
      "  Batch 2,840  of  3,145.    Elapsed: 0:27:37.\n",
      "  Batch 2,880  of  3,145.    Elapsed: 0:28:01.\n",
      "  Batch 2,920  of  3,145.    Elapsed: 0:28:24.\n",
      "  Batch 2,960  of  3,145.    Elapsed: 0:28:47.\n",
      "  Batch 3,000  of  3,145.    Elapsed: 0:29:11.\n",
      "  Batch 3,040  of  3,145.    Elapsed: 0:29:34.\n",
      "  Batch 3,080  of  3,145.    Elapsed: 0:29:57.\n",
      "  Batch 3,120  of  3,145.    Elapsed: 0:30:21.\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:30:35\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  3,145.    Elapsed: 0:00:23.\n",
      "  Batch    80  of  3,145.    Elapsed: 0:00:47.\n",
      "  Batch   120  of  3,145.    Elapsed: 0:01:10.\n",
      "  Batch   160  of  3,145.    Elapsed: 0:01:33.\n",
      "  Batch   200  of  3,145.    Elapsed: 0:01:57.\n",
      "  Batch   240  of  3,145.    Elapsed: 0:02:20.\n",
      "  Batch   280  of  3,145.    Elapsed: 0:02:43.\n",
      "  Batch   320  of  3,145.    Elapsed: 0:03:07.\n",
      "  Batch   360  of  3,145.    Elapsed: 0:03:30.\n",
      "  Batch   400  of  3,145.    Elapsed: 0:03:53.\n",
      "  Batch   440  of  3,145.    Elapsed: 0:04:17.\n",
      "  Batch   480  of  3,145.    Elapsed: 0:04:40.\n",
      "  Batch   520  of  3,145.    Elapsed: 0:05:03.\n",
      "  Batch   560  of  3,145.    Elapsed: 0:05:27.\n",
      "  Batch   600  of  3,145.    Elapsed: 0:05:50.\n",
      "  Batch   640  of  3,145.    Elapsed: 0:06:13.\n",
      "  Batch   680  of  3,145.    Elapsed: 0:06:37.\n",
      "  Batch   720  of  3,145.    Elapsed: 0:07:00.\n",
      "  Batch   760  of  3,145.    Elapsed: 0:07:23.\n",
      "  Batch   800  of  3,145.    Elapsed: 0:07:47.\n",
      "  Batch   840  of  3,145.    Elapsed: 0:08:10.\n",
      "  Batch   880  of  3,145.    Elapsed: 0:08:33.\n",
      "  Batch   920  of  3,145.    Elapsed: 0:08:57.\n",
      "  Batch   960  of  3,145.    Elapsed: 0:09:20.\n",
      "  Batch 1,000  of  3,145.    Elapsed: 0:09:43.\n",
      "  Batch 1,040  of  3,145.    Elapsed: 0:10:07.\n",
      "  Batch 1,080  of  3,145.    Elapsed: 0:10:30.\n",
      "  Batch 1,120  of  3,145.    Elapsed: 0:10:53.\n",
      "  Batch 1,160  of  3,145.    Elapsed: 0:11:17.\n",
      "  Batch 1,200  of  3,145.    Elapsed: 0:11:40.\n",
      "  Batch 1,240  of  3,145.    Elapsed: 0:12:03.\n",
      "  Batch 1,280  of  3,145.    Elapsed: 0:12:27.\n",
      "  Batch 1,320  of  3,145.    Elapsed: 0:12:50.\n",
      "  Batch 1,360  of  3,145.    Elapsed: 0:13:13.\n",
      "  Batch 1,400  of  3,145.    Elapsed: 0:13:37.\n",
      "  Batch 1,440  of  3,145.    Elapsed: 0:14:00.\n",
      "  Batch 1,480  of  3,145.    Elapsed: 0:14:23.\n",
      "  Batch 1,520  of  3,145.    Elapsed: 0:14:47.\n",
      "  Batch 1,560  of  3,145.    Elapsed: 0:15:10.\n",
      "  Batch 1,600  of  3,145.    Elapsed: 0:15:33.\n",
      "  Batch 1,640  of  3,145.    Elapsed: 0:15:57.\n",
      "  Batch 1,680  of  3,145.    Elapsed: 0:16:20.\n",
      "  Batch 1,720  of  3,145.    Elapsed: 0:16:43.\n",
      "  Batch 1,760  of  3,145.    Elapsed: 0:17:07.\n",
      "  Batch 1,800  of  3,145.    Elapsed: 0:17:30.\n",
      "  Batch 1,840  of  3,145.    Elapsed: 0:17:53.\n",
      "  Batch 1,880  of  3,145.    Elapsed: 0:18:17.\n",
      "  Batch 1,920  of  3,145.    Elapsed: 0:18:40.\n",
      "  Batch 1,960  of  3,145.    Elapsed: 0:19:03.\n",
      "  Batch 2,000  of  3,145.    Elapsed: 0:19:27.\n",
      "  Batch 2,040  of  3,145.    Elapsed: 0:19:50.\n",
      "  Batch 2,080  of  3,145.    Elapsed: 0:20:13.\n",
      "  Batch 2,120  of  3,145.    Elapsed: 0:20:37.\n",
      "  Batch 2,160  of  3,145.    Elapsed: 0:21:00.\n",
      "  Batch 2,200  of  3,145.    Elapsed: 0:21:23.\n",
      "  Batch 2,240  of  3,145.    Elapsed: 0:21:47.\n",
      "  Batch 2,280  of  3,145.    Elapsed: 0:22:10.\n",
      "  Batch 2,320  of  3,145.    Elapsed: 0:22:33.\n",
      "  Batch 2,360  of  3,145.    Elapsed: 0:22:57.\n",
      "  Batch 2,400  of  3,145.    Elapsed: 0:23:20.\n",
      "  Batch 2,440  of  3,145.    Elapsed: 0:23:43.\n",
      "  Batch 2,480  of  3,145.    Elapsed: 0:24:07.\n",
      "  Batch 2,520  of  3,145.    Elapsed: 0:24:30.\n",
      "  Batch 2,560  of  3,145.    Elapsed: 0:24:53.\n",
      "  Batch 2,600  of  3,145.    Elapsed: 0:25:17.\n",
      "  Batch 2,640  of  3,145.    Elapsed: 0:25:40.\n",
      "  Batch 2,680  of  3,145.    Elapsed: 0:26:03.\n",
      "  Batch 2,720  of  3,145.    Elapsed: 0:26:27.\n",
      "  Batch 2,760  of  3,145.    Elapsed: 0:26:50.\n",
      "  Batch 2,800  of  3,145.    Elapsed: 0:27:13.\n",
      "  Batch 2,840  of  3,145.    Elapsed: 0:27:37.\n",
      "  Batch 2,880  of  3,145.    Elapsed: 0:28:00.\n",
      "  Batch 2,920  of  3,145.    Elapsed: 0:28:23.\n",
      "  Batch 2,960  of  3,145.    Elapsed: 0:28:47.\n",
      "  Batch 3,000  of  3,145.    Elapsed: 0:29:10.\n",
      "  Batch 3,040  of  3,145.    Elapsed: 0:29:33.\n",
      "  Batch 3,080  of  3,145.    Elapsed: 0:29:57.\n",
      "  Batch 3,120  of  3,145.    Elapsed: 0:30:20.\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:30:34\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.67\n",
      "  Validation took: 0:00:58\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "     # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "               # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "                \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlUmmQVsWosG",
    "outputId": "52f0d6bc-6020-4b3a-833d-b53437662912"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGri038bWosG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(test.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = test.inspection_text.values\n",
    "labels = test.label.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPwpSlnhWosG",
    "outputId": "08a0539d-2e6a-49ac-e770-ce0fbf230452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_save/tokenizer_config.json',\n",
       " './model_save/special_tokens_map.json',\n",
       " './model_save/vocab.txt',\n",
       " './model_save/added_tokens.json')"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpPHErZZWosH"
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# Save Model and Plots\n",
    "##############################\n",
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHAYz4rKWosH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
